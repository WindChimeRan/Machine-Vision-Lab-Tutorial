{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.728672522274\n",
      "-0.00102072227502\n",
      "-0.000481828281332\n",
      "-0.000313794774171\n",
      "-0.000232105381138\n",
      "-0.00018388394611\n",
      "-0.000152083149864\n",
      "-0.000129544529681\n",
      "-0.000112739263188\n",
      "-9.97275945452e-05\n",
      "-8.93553382484e-05\n",
      "-8.0892982662e-05\n",
      "-7.38569405512e-05\n",
      "-6.79140420596e-05\n",
      "-6.28273126833e-05\n",
      "-5.84236201225e-05\n",
      "-5.45735506163e-05\n",
      "-5.11784425701e-05\n",
      "-4.81617745316e-05\n",
      "-4.54632923439e-05\n",
      "-4.30349104179e-05\n",
      "-4.08377919444e-05\n",
      "-3.88402305859e-05\n",
      "-3.70160882417e-05\n",
      "-3.53436257486e-05\n",
      "-3.3804615876e-05\n",
      "-3.2383662203e-05\n",
      "-3.10676702286e-05\n",
      "-2.98454324725e-05\n",
      "-2.87072999266e-05\n",
      "-2.76449196255e-05\n",
      "-2.66510233443e-05\n",
      "-2.57192561994e-05\n",
      "-2.48440366574e-05\n",
      "-2.40204414605e-05\n",
      "-2.32441104677e-05\n",
      "-2.25111675219e-05\n",
      "-2.18181542975e-05\n",
      "-2.11619747231e-05\n",
      "-2.05398480699e-05\n",
      "-1.99492691766e-05\n",
      "-1.9387974582e-05\n",
      "-1.88539135702e-05\n",
      "-1.83452233192e-05\n",
      "-1.78602074919e-05\n",
      "-1.73973177239e-05\n",
      "-1.69551375634e-05\n",
      "-1.65323684889e-05\n",
      "-1.61278176977e-05\n",
      "-1.57403874061e-05\n",
      "[ 0.99996307]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_x = np.array([\n",
    "    [0,0,1],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,1],\n",
    "    [0,0,0],\n",
    "    [0,1,0],\n",
    "    [1,0,0],\n",
    "    [1,1,0]\n",
    "])\n",
    "train_y = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0]\n",
    "])\n",
    "\n",
    "def _sigmoid(x,der = False):\n",
    "    \n",
    "    if der == True:\n",
    "        return x*(1-x)\n",
    "\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def _tanh(x,der = False):\n",
    "    \n",
    "    if der == True:\n",
    "        return 1-(x*x)\n",
    "\n",
    "    return np.tanh(x)\n",
    "\n",
    "def _relu(x,der = False):\n",
    "    \n",
    "    if der ==True:\n",
    "        return 1*(x>0)\n",
    "    \n",
    "    return x*(x>0)\n",
    "\n",
    "\n",
    "activation = _sigmoid \n",
    "\n",
    "def train():\n",
    "\n",
    "    \n",
    "    \n",
    "    i = 3+1\n",
    "    o = 1\n",
    "    \n",
    "    # hyperparameter\n",
    "\n",
    "    num = 50000\n",
    "    h = 4\n",
    "    batch_size = 8\n",
    "    \n",
    "    # add_b\n",
    "    x_with_b = np.column_stack((train_x,np.ones(batch_size)))\n",
    "    \n",
    "    #parameter\n",
    "    w0 = 2*np.random.random((i,h))-1\n",
    "    w1 = 2*np.random.random((h,o))-1\n",
    "    \n",
    "\n",
    "    for epoch in range(num):\n",
    "\n",
    "        # feed forward\n",
    "        l0 = x_with_b                           # (batch_size,i)\n",
    "        l1 = activation(l0.dot(w0))             # (batch_size,h)\n",
    "        l2 = activation(l1.dot(w1))             # (batch_size,o)\n",
    "\n",
    "        #loss\n",
    "        # loss = 1/2*(train_y - l2)**2\n",
    "        loss = train_y*np.log(l2) + (1-train_y)*np.log(1-l2)\n",
    "        \n",
    "        # back propagate\n",
    "        # l2_err = (train_y - l2)/(l2*(1-l2))                      # (batch_size,o)\n",
    "        # l2_delta = l2_err*activation(l2,der=True)  # (batch_size,o)\n",
    "        \n",
    "        l2_delta = train_y - l2\n",
    "        \n",
    "        l1_err = l2_delta.dot(w1.T)                # (batch_size,h)\n",
    "        l1_delta = l1_err*activation(l1,der=True)  # (batch_size,h)\n",
    "        \n",
    "        \n",
    "\n",
    "        ## update parameter\n",
    "        w1 += l1.T.dot(l2_delta)\n",
    "        w0 += l0.T.dot(l1_delta)\n",
    "        \n",
    "        if epoch%1000 == 0:\n",
    "            print(np.mean(loss))\n",
    "\n",
    "        parameter = (w0,w1)\n",
    "        \n",
    "    return parameter\n",
    "\n",
    "def inference(parameter,x):\n",
    "    \n",
    "        w0,w1 = parameter\n",
    "\n",
    "        l0 = np.array(x+[1])                     # (batch_size,i)\n",
    "        l1 = activation(l0.dot(w0))              # (batch_size,h)\n",
    "        l2 = activation(l1.dot(w1))              # (batch_size,o)\n",
    "\n",
    "        return l2\n",
    "\n",
    "test_x = [0,1,1]\n",
    "\n",
    "parameter = train()\n",
    "pre_y = inference(parameter,test_x)\n",
    "print(pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
